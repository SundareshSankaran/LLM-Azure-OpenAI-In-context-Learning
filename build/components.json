{
    "showPageContentOnly": true,
    "pages": [
        {
            "id": "params",
            "type": "page",
            "label": "Parameters",
            "children": [
                {
                    "id": "section_input_params",
                    "type": "section",
                    "label": "Parameters",
                    "open": true,
                    "children": [
                        {
                            "id": "inputData",
                            "type": "inputtable",
                            "label": "Select input data:",
                            "required": true,
                            "placeholder": "",
                            "visible": ""
                        },
                        {
                            "id": "textCol",
                            "type": "columnselector",
                            "label": "Select text column:",
                            "include": null,
                            "order": false,
                            "columntype": "a",
                            "max": null,
                            "min": null,
                            "visible": "",
                            "table": "inputData"
                        },
                        {
                            "id": "docId",
                            "type": "columnselector",
                            "label": "Select ID column:",
                            "include": null,
                            "order": false,
                            "columntype": "a",
                            "max": null,
                            "min": null,
                            "visible": "",
                            "table": "inputData"
                        },
                        {
                            "id": "copyVarList",
                            "type": "columnselector",
                            "label": "Select additional columns to copy over:",
                            "include": null,
                            "order": false,
                            "columntype": "a",
                            "max": null,
                            "min": null,
                            "visible": "",
                            "table": "inputData"
                        },
                        {
                            "id": "section_prompts",
                            "type": "section",
                            "label": "Prompts",
                            "open": true,
                            "children": [
                                {
                                    "id": "systemPrompt",
                                    "type": "textarea",
                                    "label": "Provide system prompt:",
                                    "placeholder": "",
                                    "required": false,
                                    "visible": ""
                                },
                                {
                                    "id": "text_system_prompt",
                                    "type": "text",
                                    "text": "Use the system prompt to provide broad instructions to the LLM such as role, task description and response specification.",
                                    "visible": ""
                                },
                                {
                                    "id": "userPrompt",
                                    "type": "textarea",
                                    "label": "Provide user prompt:",
                                    "placeholder": "",
                                    "required": false,
                                    "visible": ""
                                },
                                {
                                    "id": "text_user_prompt",
                                    "type": "text",
                                    "text": "Use the user prompt to provide specific instructions on the task to perform.  Use tags like {Question}, {Context} etc. to refer to the context provided.",
                                    "visible": ""
                                },
                                {
                                    "id": "userExample",
                                    "type": "textarea",
                                    "label": "Provide illustrative example(s):",
                                    "placeholder": "",
                                    "required": false,
                                    "visible": ""
                                },
                                {
                                    "id": "text_user_example",
                                    "type": "text",
                                    "text": "Use the user example to provide 0, 1, or more illustrative examples of context and desired response from the LLM. Tag examples as Example: and Answer:.",
                                    "visible": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "section_output_specs",
                    "type": "section",
                    "label": "Output specification",
                    "open": true,
                    "visible": "",
                    "children": [
                        {
                            "id": "temperature",
                            "type": "numstepper",
                            "label": "Select temperature for output:",
                            "required": false,
                            "integer": false,
                            "min": null,
                            "max": null,
                            "stepsize": 1
                        },
                        {
                            "id": "text_temperature",
                            "type": "text",
                            "text": "Use the temperature control to govern how the LLM generates its response based on next word prediction.",
                            "visible": ""
                        },
                        {
                            "id": "outputTable",
                            "type": "outputtable",
                            "label": "Provide output table:",
                            "required": true,
                            "placeholder": "",
                            "visible": ""
                        }
                    ]
                }
            ]
        },
        {
            "id": "config",
            "type": "page",
            "label": "Configuration",
            "children": [
                {
                    "id": "section_gen_model",
                    "type": "section",
                    "label": "Text generation model",
                    "open": true,
                    "children": [
                        {
                            "id": "genModelDeployment",
                            "type": "textfield",
                            "label": "Provide name of your Azure OpenAI generation model deployment:",
                            "placeholder": "",
                            "required": true,
                            "visible": ""
                        }
                    ]
                },
                {
                    "id": "section_azure_openai",
                    "type": "section",
                    "label": "Azure OpenAI service:",
                    "open": true,
                    "children": [
                        {
                            "id": "azureKeyLocation",
                            "type": "path",
                            "label": "Provide path to your Azure OpenAI key:",
                            "pathtype": "file",
                            "placeholder": "",
                            "required": false,
                            "visible": ""
                        },
                        {
                            "id": "text_key_details",
                            "type": "text",
                            "text": "Ensure this key is located in a file saved in a secure folder.",
                            "visible": ""
                        },
                        {
                            "id": "azureOpenAIEndpoint",
                            "type": "textfield",
                            "label": "Provide URL for Azure OpenAI service endpoint:",
                            "placeholder": "",
                            "required": true,
                            "visible": ""
                        },
                        {
                            "id": "azureRegion",
                            "type": "textfield",
                            "label": "Provide region for Azure OpenAI service",
                            "placeholder": "Default value: eastus2",
                            "required": false,
                            "visible": ""
                        },
                        {
                            "id": "openAIVersion",
                            "type": "textfield",
                            "label": "OpenAI API Version",
                            "placeholder": "2024-10-21",
                            "required": false,
                            "visible": ""
                        }
                    ]
                }
            ]
        },
        {
            "id": "about",
            "type": "page",
            "label": "About",
            "children": [
                {
                    "id": "about_description",
                    "type": "text",
                    "text": "LLM - Azure OpenAI In-context Learning==============================================This custom step helps you interact with a Large Language Model (LLM) calling an [Azure OpenAI](https://microsoftlearning.github.io/mslearn-openai/Instructions/Exercises/01-get-started-azure-openai.html) service to process simple instructions on specified input data. It uses an approach called In-context learning which uses provided examples to perform a task.  If no example is provided, then the LLM simply uses the provided context.  This is useful for cases where a call to an LLM does not require prior search, filter or query of data sources (such as what Retrieval Augmented Generation provides) . Run inside a SAS session, this custom step takes either a SAS dataset or a CAS table as input and returns a SAS dataset (or CAS table) as output, with the response added as a new variable.",
                    "visible": ""
                },
                {
                    "id": "section_prereqs",
                    "type": "section",
                    "label": "Prerequisites",
                    "open": false,
                    "visible": "",
                    "children": [
                        {
                            "id": "text_prereqs",
                            "type": "text",
                            "text": "1. Python is available to the SAS Viya Compute session.  2. Python packages to be installed:   i.  openai: https://pypi.org/project/openai/  ii.   pandas: https://pypi.org/project/pandas/  3. Viya 4 environment version 2025.01 or later 4. Valid Azure OpenAI service with large language models deployed.  Refer here for instructions: https://learn.microsoft.com/en-us/azure/ai-services/openai/quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-studio",
                            "visible": ""
                        }
                    ]
                },
                {
                    "id": "section_assumptions",
                    "type": "section",
                    "label": "Assumptions",
                    "open": false,
                    "visible": "",
                    "children": [
                        {
                            "id": "text_assumptions",
                            "type": "text",
                            "text": "Current assumptions for this initial versions (future versions may improve upon the same):1. Users  choose either a SAS dataset or Cloud Analytics Services (CAS) table as their input 2. User has already configured Azure OpenAI to deploy both an embedding function and LLM service, or knows the deployment names.",
                            "visible": ""
                        }
                    ]
                },
                {
                    "id": "about_parameters",
                    "type": "section",
                    "label": "Parameters",
                    "open": true,
                    "visible": "",
                    "children": [
                        {
                            "id": "parameters_input",
                            "type": "section",
                            "label": "Input parameters",
                            "open": true,
                            "visible": "",
                            "children": [
                                {
                                    "id": "input_parameters_text",
                                    "type": "text",
                                    "text": "1. Input Data (input port, required): attach either a SAS dataset or a CAS table to the same.\n2. Text column (column selector, required): select one column containing text to serve as context\n3. ID column (column selector, required): select an ID column\n4. System prompt (text area, required, boilerplate default): Provide a system prompt which is used to provide broad instructions about persona, range of tasks and response specification for LLM\n5. User prompt (text area, required, boilerplate default): Provide a user prompt which specifies the task to perform\n6. Illustrative example (text area, optional): Provide an example of task and response to help the LLM understand how to process instructions.\n",
                                    "visible": ""
                                }
                            ]
                        },
                        {
                            "id": "parameters_output_specs",
                            "type": "section",
                            "label": "Output specifications",
                            "open": false,
                            "visible": "",
                            "children": [
                                {
                                    "id": "output_parameters_text",
                                    "type": "text",
                                    "text": "1. Temperature (numeric stepper, default 0): temperature for an LLM affects its abiity to predict the next word when generating responses.  A rule of thumb is that a temperature closer to 0 indicates the model uses the predicted next word with the highest probability, whereas a temperature of 1 increases the randomness with which the model predicts the next word.  \n2. Output table (output port, required): attach either a CAS table or sas7bdat to the output port of this node to hold results.  These results contain the LLM's answer, the original question and columns carried along.",
                                    "visible": ""
                                }
                            ]
                        },
                        {
                            "id": "parameters_config",
                            "type": "section",
                            "label": "Configuration ",
                            "open": 1,
                            "visible": "",
                            "children": [
                                {
                                    "id": "output_parameters_text_1",
                                    "type": "text",
                                    "text": "1. Text generation model (text field, required): provide the name of an Azure OpenAI text generation deployment.  For convenience, you may choose to use the same name as the OpenAI LLM. Example, gpt-35-turbo to gpt-35-turbo.\n2. Azure OpenAI service details (file selector for key and text fields, required): provide a path to your Azure OpenAI access key.  Ensure this key is saved within a text file in a secure location on the filesystem.  Users are responsible for providing their keys to use this service.  In addition, also refer to your Azure OpenAI service to obtain the service endpoint and region. The OpenAI API version can be changed if required.",
                                    "visible": ""
                                }
                            ]
                        }
                    ]
                },
                {
                    "id": "about_runtimecontrol",
                    "type": "section",
                    "label": "Run-time Control",
                    "open": 0,
                    "visible": "",
                    "children": [
                        {
                            "id": "runtimecontrol_text",
                            "type": "text",
                            "text": "Note: Run-time control is optional.  You may choose whether to execute the main code of this step or not, based on upstream conditions set by earlier SAS programs.  This includes nodes run prior to this custom step earlier in a SAS Studio Flow, or a previous program in the same session.Refer this blog (https://communities.sas.com/t5/SAS-Communities-Library/Switch-on-switch-off-run-time-control-of-SAS-Studio-Custom-Steps/ta-p/885526) for more details on the concept.The following macro variable,_aor_run_triggerwill initialize with a value of 1 by default, indicating an \"enabled\" status and allowing the custom step to run.If you wish to control execution of this custom step, include code in an upstream SAS program to set this variable to 0.  This \"disables\" execution of the custom step.To \"disable\" this step, run the following code upstream:%global _aicl_run_trigger;%let _aicl_run_trigger =0;To \"enable\" this step again, run the following (it's assumed that this has already been set as a global variable):%let _aicl_run_trigger =1;IMPORTANT: Be aware that disabling this step means that none of its main execution code will run, and any  downstream code which was dependent on this code may fail.  Change this setting only if it aligns with the objective of your SAS Studio program.",
                            "visible": ""
                        }
                    ]
                },
                {
                    "id": "about_documentation",
                    "type": "section",
                    "label": "Documentation",
                    "open": 0,
                    "visible": "",
                    "children": [
                        {
                            "id": "documentation_text",
                            "type": "text",
                            "text": "1.  Azure OpenAI service: https://learn.microsoft.com/en-us/azure/ai-services/openai/\n2.  SAS Communities article on configuring Viya for Python integration: https://communities.sas.com/t5/SAS-Communities-Library/Configuring-SAS-Viya-for-Python-Integration/ta-p/847459\n3. The SAS Viya Platform Deployment Guide (refer to SAS Configurator for Open Source within): https://go.documentation.sas.com/doc/en/itopscdc/default/itopssr/p1n66p7u2cm8fjn13yeggzbxcqqg.htm?fromDefault=#p19cpvrrjw3lurn135ih46tjm7oi \n4. OpenAI API versions change periodically. Keep track of them here: https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation",
                            "visible": ""
                        }
                    ]
                },
                {
                    "id": "version_text",
                    "type": "text",
                    "text": "Version: 1.0  (24FEB2025)",
                    "visible": ""
                },
                {
                    "id": "contact_text",
                    "type": "text",
                    "text": "Created/contact: \n- Sundaresh Sankaran (sundaresh.sankaran@sas.com) \n- Crystal Baker (crystal.baker@sas.com)",
                    "visible": ""
                }
            ]
        }
    ],
    "values": {
        "inputData": {
            "library": "",
            "table": ""
        },
        "textCol": [],
        "docId": [],
        "copyVarList": [],
        "systemPrompt": "",
        "userPrompt": "",
        "temperature": null,
        "outputTable": {
            "library": "",
            "table": ""
        },
        "genModelDeployment": "",
        "azureKeyLocation": "",
        "azureOpenAIEndpoint": "https://<your_openai_service>.azure.com/",
        "azureRegion": "eastus2",
        "openAIVersion": "2024-10-21"
    }
}