{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai\n",
    "\n",
    "# imports\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client(endpoint = None, api_key = None, api_version = None): \n",
    "    import os\n",
    "    from openai import AzureOpenAI\n",
    "    if endpoint is None:\n",
    "        endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    if api_key is None:\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    if api_version is None:\n",
    "        api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=api_version, \n",
    "        azure_endpoint=endpoint\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client(api_version= \"2023-05-15\", api_key='dfsaf', endpoint='sfada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(system_prompt = None, user_prompt = None, example = None):\n",
    "    if system_prompt is None:\n",
    "        system_prompt = \"You are a helpful assistant.\"\n",
    "    if user_prompt is None:\n",
    "        user_prompt = \"Summarize the following text.\"\n",
    "    if example is None:\n",
    "        example= \"\"\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question: {user_prompt}. Example(s): {example} \\n\"\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_prompt(system_prompt=None, user_prompt=None, example=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1][\"content\"] = x[1][\"content\"] + \"fdsahklgjkfld;jgk;lfdjkl;a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Summarize the following text.. Example(s):  \n",
      "fdsahklgjkfld;jgk;lfdjkl;a\n"
     ]
    }
   ],
   "source": [
    "print(x[1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize authentification credentials\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://oai-test-ss.openai.azure.com/\")\n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-35-turbo\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"f280112d275040608311f2920c9f1a28\")\n",
    "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \n",
    "# os.environ[\"DEPLOYMENT_NAME\"] = SAS.SYMGET(\"genModelDeployment\")\n",
    "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = SAS.SYMGET(\"azureOpenAIEndpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Question: Summarize the following text.. Example(s): fdsahklgjkfld;jgk;lfdjkl;a'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain values from UI\n",
    "system_prompt = \"you are a helpful library assistant. For each description of a book, provide the genre of the book.\"\n",
    "input_data = pd.read_csv(\"book_desc.csv\")\n",
    "doc_id = \"title\"\n",
    "text_col = \"description\"\n",
    "user_prompt = \"{Question}What is the genre of this book? {Context} \"\n",
    "temperature = 0.7\n",
    "output_table = pd.DataFrame(columns=[])\n",
    "# input_data= SAS.symget(\"inputData\")\n",
    "# output_table = SAS.symget(\"outputTable\")\n",
    "# system_prompt = SAS.symget(\"system_prompt\")\n",
    "# user_prompt = SAS.symget(\"user_prompt\")\n",
    "# text_col = SAS.symget(\"textcol\")\n",
    "# temperature = SAS.symget(temperature)\n",
    "# shots = SAS.symget(\"shots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-10-21\", \n",
    "    azure_endpoint=endpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(context): \n",
    "    # generate prompt\n",
    "    chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt + context \n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    # call the llm \n",
    "    completion = client.chat.completions.create(\n",
    "        model = deployment,\n",
    "        messages = chat_prompt,\n",
    "        temperature = temperature\n",
    "    )  \n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input[\"response\"]= input_data[text_col].apply(call_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fantasy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mystery/Thriller.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romance/Contemporary Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       response\n",
       "0                      Fantasy.\n",
       "1             Mystery/Thriller.\n",
       "2  Romance/Contemporary Fiction"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multicolumn assignment\n",
    "def call_llm(row): \n",
    "    # generate prompt\n",
    "    chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_prompt + row[text_col] \n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    # call the llm \n",
    "    completion = client.chat.completions.create(\n",
    "        model = deployment,\n",
    "        messages = chat_prompt,\n",
    "        temperature = temperature\n",
    "    )  \n",
    "    return completion.choices[0].message.content, completion.choices[0].finish_reason, completion.choices[0].content_filter_results['hate']['severity'], completion.choices[0].content_filter_results['self_harm']['severity'], completion.choices[0].content_filter_results['sexual']['severity'], completion.choices[0].content_filter_results['violence']['severity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data[['response', 'finish_reason', 'response_hate', 'response_self_harm', 'response_sexual', 'response_violence']] = input_data.apply(call_llm, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>response</th>\n",
       "      <th>finish_reason</th>\n",
       "      <th>response_hate</th>\n",
       "      <th>response_self_harm</th>\n",
       "      <th>response_sexual</th>\n",
       "      <th>response_violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Onyx Storm</td>\n",
       "      <td>Rebecca Yarros</td>\n",
       "      <td>After nearly eighteen months at Basgiath War C...</td>\n",
       "      <td>The genre of this book is fantasy.</td>\n",
       "      <td>stop</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beautiful Ugly</td>\n",
       "      <td>Alice Feeney</td>\n",
       "      <td>Author Grady Green is having the worst best da...</td>\n",
       "      <td>The genre of this book is Mystery/Thriller.</td>\n",
       "      <td>stop</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Big Beautiful Life</td>\n",
       "      <td>Emily Henry</td>\n",
       "      <td>Alice Scott is an eternal optimist still dream...</td>\n",
       "      <td>The genre of this book is romance.</td>\n",
       "      <td>stop</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title          author  \\\n",
       "0                Onyx Storm  Rebecca Yarros   \n",
       "1            Beautiful Ugly    Alice Feeney   \n",
       "2  Great Big Beautiful Life     Emily Henry   \n",
       "\n",
       "                                         description  \\\n",
       "0  After nearly eighteen months at Basgiath War C...   \n",
       "1  Author Grady Green is having the worst best da...   \n",
       "2  Alice Scott is an eternal optimist still dream...   \n",
       "\n",
       "                                      response finish_reason response_hate  \\\n",
       "0           The genre of this book is fantasy.          stop          safe   \n",
       "1  The genre of this book is Mystery/Thriller.          stop          safe   \n",
       "2           The genre of this book is romance.          stop          safe   \n",
       "\n",
       "  response_self_harm response_sexual response_violence  \n",
       "0               safe            safe              safe  \n",
       "1               safe            safe              safe  \n",
       "2               safe            safe              safe  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-AtJE2DWzZ6YmFIu0PqQRGQrIKVuv5\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! How can I assist you today?\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1737745306,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 9,\n",
      "    \"prompt_tokens\": 37,\n",
      "    \"total_tokens\": 46\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
